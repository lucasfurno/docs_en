---
layout: page-documentation-md
title: Data Streaming
description: Data Streaming is an Edge Analytics product that allows you to feed your SIEM, big data and stream processing platforms with access to your content and applications data, in real time, adding even more intelligence to your business.
meta_tags: data, streaming,  edge computing

namespace:     documentation_products_data_streaming

permalink: "/documentation/products/data-streaming/"
permalink_pt-br: "/documentacao/produtos/data-streaming/"
---

# Data **Streaming**

[Edit on GitHub <svg width="14" height="14" xmlns="http://www.w3.org/2000/svg"><g fill="none" stroke="#F3652B"><path d="M4.81.71H.672v11.43H12.1V8.001" stroke-width=".8"/><path d="M6.87.786h5.155V5.94M6.31 6.5L12.026.786"/></g></svg>](https://github.com/aziontech/docs_en/edit/master/data-streaming/2021-01-14-index.md)

Data Streaming is an Edge Analytics product that allows you to feed your SIEM, big data and stream processing platforms with access to your content and applications data, in real time, adding even more intelligence to your business.

This integration allows you to analyze the behavior of your users and the performance of your content, applications and troubleshooting, in a simple and agile way.

  > 1. [Accessing Data Streaming](#AccessingDataStreaming)
  > 2. [Selecting Data Sources](#SelectingDataSources)
  > 3. [Using a Template](#UsingaTemplate)
  > 4. [Associating Domains](#AssociatingDomains)
  > 5. [Setting the Endpoint](#Settingtheendpoint)
  > 6. [Customizing the Payload](#CustomizingthePayload)
  > 7. [Activating your Settings](#ActivatingyourSettings)

---

## 1. Accessing Data Streaming {#Accessing-data-streaming}

Enter [Real-Time Manager](https://manager.azion.com/). Click on *Data Streaming* either under Edge Analytics or through the Products menu. 

Configure your Data Streaming settings according to the following possibilities. 

> Fields marked with an asterisk are required. 

---

## 2. Selecting Data Sources {#selecting-data-sources}

The first step is choosing the Data Source, which represents the application at Azion that generated the event logs. By doing so, you must select where your data will be collected from. You have the following options:

### **Edge Applications**

It displays the data from requests made to your Edge Applications at Azion.

| Variables                        | Description                                                  |
| -------------------------------- | ------------------------------------------------------------ |
| $bytes_sent                      | Bytes sent to the user, including header and body.           |
| $client                          | Unique Azion customer identifier.                            |
| $configuration                   | Unique Azion configuration identifier.                       |
| $country                         | Country name of the remote client, for example “Russian Federation”, “United States”. Geolocation detection by IP address. |
| $host                            | Host information sent on the request line; or HTTP header Host field. |
| $http_referrer                   | Information from the last page the user was on before making the request. |
| $http_user_agent                 | The identification of the application that made the request, for example: Mozilla/5.0 (Windows NT 10.0; Win64; x64). |
| $proxy_status                    | HTTP Status Code of origin (”-” in case of cache).           |
| $remote_addr                     | IP address of the request.                                   |
| $remote_port                     | Remote port of the request.                                  |
| $request_length                  | Request size, including request line, headers and body.      |
| $request_method                  | Request method; usually “GET” or “POST”.                     |
| $request_time                    | Request processing time with resolution in milliseconds.     |
| $request_uri                     | URI of the request made by the user, without the Host and Protocol information. |
| $requestPath                     | The request URI without Query String, Host and Protocol information. |
| $requestQuery                    | Only the URI parameters of the request.                      |
| $scheme                          | Request scheme “http” or “https".                            |
| $sent_http_content_type          | “Content-Type” header sent in the origin’s response.         |
| $sent_http_x_original_image_size | “X-Original-Image-Size” header sent in the origin’s response (used by IMS to inform original image size). |
| $server_protocol                 | The protocol of the connection established, usually “HTTP/1.1” or “HTTP/2.0”. |
| $ssl_cipher                      | Cipher string used to establish SSL connection.              |
| $ssl_protocol                    | The protocol for an established SSL connection, for example “TLS v1.2”. |
| *$state                          | Name of the remote client’s state, for example: “RS”, “SP”. <br/>Geolocation detection of IP address. |
| $status                          | The status code of the request, for example: 200.            |
| $tcpinfo_rtt                     | The RTT time in microseconds measured by Edge for the user.  |
| $time                            | Request date and time.                                       |
| $upstream_bytes_received         | Number of bytes received by the origin’s Edge, if the content is not cached. |
| $upstream_cache_status           | Status of the Edge cache. It can assume the values “MISS”, “BYPASS”, “EXPIRED”, “STALE”, “UPDATING”, “REVALIDATED” or “HIT”. |
| $upstream_connect_time           | Time in milliseconds for Edge to establish a connection with the origin (“0” in case of KeepAlive and “-“ in case of cache). |
| $upstream_header_time            | Time in milliseconds for Edge to receive the origin’s response headers ( “-“ in case of cache). |
| $upstream_response_time          | Time in milliseconds for Edge to receive all of the response from the origin, including headers and body (“-“ in case of cache). |
| $upstream_status                 | HTTP Status Code of the origin (“-“ in case of cache).       |
| $waf_attack_action               | It reports WAF’s action regarding the action ($BLOCK, $PASS, $LEARNING_BLOCK, $LEARNING_PASS). |
| $waf_attack_family               | It informs the classification of the WAF infraction detected in the request (SQL, XSS, TRAVERSAL, among others). |

### **WAF**

If you have contracted the [Web Application Firewall](https://www.azion.com/pt-br/docs/produtos/web-application-firewall/) product, the WAF Events data source will display the requests analyzed by WAF to allow you to map the score assigned to the request, the WAF rules that matched, the reason for the block and more.

| Variable           | Description                                                  |
| ------------------ | ------------------------------------------------------------ |
| $blocked           | It informs whether the WAF blocked the action or not; 0 when not blocked and 1 when blocked. When in “Learning Mode”, it will not be blocked, regardless of the return. |
| $client            | Unique Azion customer identifier.                            |
| $configuration     | Unique Azion configuration identifier.                       |
| $country           | Country name of the remote client, for example “Russian Federation”, “United States”. Geolocation detection by IP address. |
| $headers           | Request headers analyzed by WAF.                             |
| $host              | Host information sent on the request line; or Host field of the HTTP header. |
| $remote_addr       | IP address of the request.                                   |
| $requestPath       | The request URI without Query String, Host and Protocol information. |
| $requestQuery      | Only the URI parameters of the request.                      |
| $server_protocol   | The protocol of the connection established, usually “HTTP/1.1” or “HTTP/2.0”. |
| $time              | Timestamp of the start of the request.                       |
| $version           | The version of Azion Log used.                               |
| $waf_args          | The request arguments.                                       |
| $waf_attack_action | It reports WAF’s action regarding the action ($BLOCK, $PASS, $LEARNING_BLOCK, $LEARNING_PASS). |
| $waf_attack_family | It informs the classification of the WAF infraction detected in the request (SQL, XSS, TRAVERSAL, among others) |
| $waf_learning      | It informs if WAF is in learning mode, usually 0 or 1.       |
| $waf_match         | List of infractions found in the request, it is formed by key-value elements; the key refers to the type of violation detected; the value shows the string that generated the infraction. |
| $waf_score         | It reports the score that will be increased in case of match. |
| $waf_server        | Hostname used in the request.                                |
| $waf_uri           | URI used in the request.                                     |

---

## 3. Using a Template {#using-a-template}

The template represents a selection of variables to be collected and a format for transfer. You can select templates created and maintained by Azion or customize your own selection.

* **Custom Template:** Choose the *Custom Template* option to create your own customized *Data Set*, in JSON format, and select the variables that best suit your needs. 

> On the [Data Sources](#SelectingDataSources) list you'll find a description of all the available variables. Give it a try.

Your events will be grouped in blocks of up to 2,000 registrations separated by the character \ n, and sent in the payload to your endpoint. Data Streaming will send your events when the block reaches 2000 records or every 60 seconds, whichever occurs first.

---

## 4. Associating Domains {#Associating-domains}

You can associate Data Streaming with one or more of your domains registered with Azion.

When associating a domain with Data Streaming, the events associated with that domain will be collected and sent to its endpoint.

You can also set the percentage of data you want to receive from your Data Streaming through the Sampling option. In addition to filtering by sampling, it can also reduce costs of data collection and analysis.

- **Sampling:**

1. Select the **All Domains** option to enable  *Sampling*.
2. Enter the number for the percentage of data you want to receive. This percentage will return the total data related to all your domains.

> When the Sampling option is enabled, you are allowed to add only one Data Streaming. If this Data Streaming is disabled, the Add Data Streaming option will be enabled again.

---

## 5. Setting the Endpoint {#Settingtheendpoint}

The Endpoint is the destination where you want to send the data collected by Azion.

The endpoint type represents the method that your endpoint is configured to receive data from the Data Streaming. Get to know each of them as follows.

### **Apache Kafka**

By using this type of endpoint, the Data Streaming service sends data to a Kafka endpoint in your infrastructure.

* **Bootstrap Servers:**  refers to the servers in the Kafka cluster, in the format "host1: port1, host2: port2, ...". 

  The list should have just a few servers that will be used for the initial connection. There is no need to include all the servers in your cluster.  

  We recommend that you use more than one server to increase redundancy and availability.

* **Kafka Topic:**  you have to define a Topic where you want Data Streaming to post messages to your cluster.

### **Elasticsearch**

By using this type of endpoint, the Data Streaming service sends data to a Elasticsearch endpoint in your infrastructure.

- **Elasticsearch URL**: (*required*) refers to the URL address plus the Elasticsearch index that will receive the data collected from Data Streaming. For example: [https://ela](https://elasticsearch-domain.com/index)[s](https://elasticsearch-domain.com/index)[ticsearch-domain.com/index](https://elasticsearch-domain.com/index).

- **API Key**: (*required*) refers to the base 64 encoded API key, used for authentication with Elasticsearch.

### **Google BigQuery**

By using this type of endpoint, the Data Streaming service sends data to a Google BigQuery endpoint in your infrastructure.

**Project ID:** refers to your project ID on Google Cloud.

**Dataset ID:** refers to your dataset ID on Google BigQuery.

**Table ID:** refers to your table ID on Google BigQuery.

**Service Account Key:** refers to the code snippet in JSON format containing the key that will be used for authentication with Google services.

### **Standard HTTP/HTTPS POST**

By using this type of endpoint, the Data Streaming service sends data in an HTTP POST payload to be  processed on your platform.

* **Endpoint URL:** refers to the URL configured on the platform to receive Data Streaming data.

   Use the format *scheme://domain/path*.

* **Custom Headers:**  you can enter one or more custom headers for your HTTP / HTTPS request. 

  For the headers configuration, you have to inform the *Name* and *Value* for each header.

### **Simple Storage Service (S3)**

By using this type of endpoint, the Data Streaming service sends data directly to any storage that works with the S3 protocol, such as Amazon S3, among others.

* **Host URL:** refers to the URL of the Host S3.

  You can connect with any provider that works with the S3 protocol.

* **Bucket Name:** refers to the name of the Bucket that the object will be sent to.

  It is important that the Bucket is already created so that Data Streaming can send the objects.

* **Region:**  refers to the region in which the Bucket is hosted. 

  For example, "us-east-1".

* **Access Key:** refers to the key to access the Bucket.

* **Secret Key:** refers to the secret key to access the Bucket.

* **Object Key Prefix:**  refers to a prefix for the sent files. 

  For example "waf_logs", then all sent objects will be saved with `"waf_logs_ <TIMESTAMP> _ <UUID>"`.

* **Content Type:** it's the format that the object will be created in the Bucket. 

  You count on the *plain/text* and *application/gzip* options.

### **Standard HTTP/HTTPS POST**

By using this type of endpoint, the Data Streaming service sends data in an HTTP POST payload to be  processed on your platform.

* **Endpoint URL:** refers to the URL configured on the platform to receive Data Streaming data.

  Use the format *scheme://domain/path*.

* **Custom Headers:**  you can enter one or more custom headers for your HTTP / HTTPS request. 

  For the headers configuration, you have to inform the *Name* and *Value* for each header.

------

## 6. Customizing the Payload {#CustomizingthePayload}

You can also customize the Payload sent by the connector according to the following options.

- Log Line Separator: (optional) defines the type of information that will be used at the end of each log line. 

- Payload Format: (optional) defines which information will be at the beginning and at the end of the dataset. 

  The following example shows how the user will receive the exit code:

```
 1 [{ "request_method": "GET", "host": "statis.exampledomain.com.br", "status": "200" },{
 2 "request_method": "GET", "host": "statis.exampledomain.com.br", "status": "200" },{ 
 3 "request_method": "GET", "host": "statis.exampledomain.com.br", "status": "200" },{ 
 4 "request_method": "GET", "host": "statis.exampledomain.com.br", "status": "200" },{ 	
 5 "request_method": "GET", "host": "statis.exampledomain.com.br", "status": "200" },{
 6 "request_method": "GET", "host": "statis.exampledomain.com.br", "status": "200" }]
 
```

> This feature is only available for the HTTP POST endpoint. 

------

## 7. Activating your Settings {#Activatingyoursettings}

You will find the following buttons at the bottom of the screen:

* **Active:** Turn on this button to enable your settings on the system. 

* **Cancel:** With this option, you return to the Data Streaming home page, also discard your edits. 

* **Save:** Once your selections are complete, save your settings by clicking the **Save** button. 



---

Didn't find what you were looking for? [Open a support ticket.](https://tickets.azion.com/)
